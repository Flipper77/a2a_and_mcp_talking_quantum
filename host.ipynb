{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d92675a482e686d",
   "metadata": {},
   "source": [
    "# Start a MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406924d06314ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "notebook_subprocesses = []\n",
    "\n",
    "# Global list to keep track of all subprocesses\n",
    "notebook_subprocesses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752a51c7f34a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Library Server (port 58002)\n",
    "proc = subprocess.Popen([\"python\", \"library_server.py\"])\n",
    "notebook_subprocesses.append(proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e083fcf7560076",
   "metadata": {},
   "source": [
    "# Smolagents MCP Client Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95667e5bb2011e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install smolagents[mcp]\n",
    "from smolagents.mcp_client import MCPClient\n",
    "\n",
    "tools_url_list = [{\"url\":\"http://localhost:58002/sse\"}]\n",
    "\n",
    "def show_tools(url_list=tools_url_list):\n",
    "    #for url in url_list:\n",
    "    try:\n",
    "        mcp_client = MCPClient(url_list)\n",
    "        tools = mcp_client.get_tools()\n",
    "        print(\"------------------------------------\")\n",
    "        for tool in tools:\n",
    "            print(\"tool.name: \", tool.name)\n",
    "            print(\"tool.description: \", tool.description)\n",
    "            print(\"tool.inputs: \",tool.inputs)\n",
    "            print(\"tool.output_type: \", tool.output_type)\n",
    "            print(\"------------------------------------\")\n",
    "        # use your tools here.\n",
    "    finally:\n",
    "        mcp_client.disconnect()\n",
    "\n",
    "show_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d236d6b14d85d3",
   "metadata": {},
   "source": [
    "# Start A2A Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f7667-31ee-4bd2-9d9b-95e7407c24af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe73ac-a1f4-49bd-b524-7030b621a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or\n",
    "openai_key = \"your-openai-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55ccf9c81eca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a2a Server with literature critic agent\n",
    "proc = subprocess.Popen([\"python\", \"literature_critic.py\", \"--url\", \"http://localhost:52042\", \"--openai-key\", openai_key])\n",
    "notebook_subprocesses.append(proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b957489a46832a",
   "metadata": {},
   "source": [
    "# Define a2a SmolAgent proxy from MultiStepAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d71b220900fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing a2a agents as proxies for smolagents\n",
    "# builds one A2AProxy per remote card\n",
    "from a2a_bootstrap_proxies import A2AProxyBootstrap\n",
    "\n",
    "agents_url_list = [\"http://localhost:52042\"]\n",
    "smolagent_managed_a2a_agents = A2AProxyBootstrap(agents_url_list).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413e78c6b2f6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------------------\")\n",
    "for agent in smolagent_managed_a2a_agents:\n",
    "    print(\"agent.name: \", agent.name)\n",
    "    print(\"agent.description: \", agent.description)\n",
    "    for skill in agent.card.skills:\n",
    "        print(\"agent.skill.name: \", skill.name)\n",
    "        print(\"agent.skill.description: \", skill.description)\n",
    "        print(\"agent.skill.tags: \", skill.tags)\n",
    "        print(\"agent.skill.examples: \", skill.examples)\n",
    "        print(\"agent.skill.inputModes: \", skill.inputModes)\n",
    "        print(\"agent.skill.outputModes: \", skill.outputModes)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f991e70f750a24c3",
   "metadata": {},
   "source": [
    "# The Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6748945cbaa732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents.models import OpenAIServerModel\n",
    "from smolagents.agents import CodeAgent\n",
    "from smolagents.monitoring import LogLevel\n",
    "\n",
    "\n",
    "model = OpenAIServerModel(\n",
    "    model_id=\"gpt-4o\", #  note that gpt-4o follows often (not always) a stringent and clear solution path without much ado and provides the correct answer. 4.5 acorns out of five.\n",
    "    api_key=openai_key,\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "def run_host_query(user_input: str, url_list=tools_url_list):\n",
    "    with MCPClient(url_list) as tools:\n",
    "        orchestrator_agent = CodeAgent(\n",
    "                                tools=tools,\n",
    "                                model=model, #ollama_model model\n",
    "                                managed_agents=smolagent_managed_a2a_agents,\n",
    "                                verbosity_level= LogLevel.DEBUG\n",
    "                            )\n",
    "        return orchestrator_agent.run(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecb643a0220bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_host_query(\"Give me a summary of the note on conservation of coffee energy, please.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d5fc232b206fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_host_query(\"Give me a literature critics review of the quantum squrrel report, please.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ee3732f3bdfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_host_query(\"Give me a literature critics review of the document on the conservation of coffee energy, please.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157f86fc8d6c35d",
   "metadata": {},
   "source": [
    "# Close a2a agent connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d042d5c280b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in smolagent_managed_a2a_agents:\n",
    "    if hasattr(agent.a2a_client, \"aclose\"):\n",
    "        await agent.a2a_client.aclose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893c1dbc6d0e6da",
   "metadata": {},
   "source": [
    "# Stop all subprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea5e186be5e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proc in notebook_subprocesses:\n",
    "    proc.terminate()  # or proc.kill() for force\n",
    "notebook_subprocesses.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e9420-94e2-4877-82d6-58957e4b9825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:a2a_talking_quantum]",
   "language": "python",
   "name": "conda-env-a2a_talking_quantum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
